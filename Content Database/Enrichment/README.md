## Algorithms in folder NLP4Stat/Enrichment

1. [**/LDA_2/topic-modeling-lda-vem-v1.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Enrichment/LDA_2/topic-modeling-lda-vem-v1.ipynb): R Jupyter notebook implementing the Latent Dirichlet Allocation (LDA) algorithm for topic modeling (Variational Expectation-Maximization -VEM also called Variational Bayes - VB) version. The texts are the contents of the Statistics Explained (SE) Glossary articles, as stored in the Knowledge Database (KD).

2. [**/LDA_2/topic-modeling-lda-gibbs-v1.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Enrichment/LDA_2/topic-modeling-lda-gibbs-v1.ipynb): R Jupyter notebook of an alternative implementation of the LDA algorithm (with package textmineR and Gibbs sampling) and some more results. The topics are quite similar with the ones with algorithm [1].  

3. [**/Spacy_NER/Glossary_NamedEntities_V3b_rev_2022.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Content%20Database/Enrichment/Spacy_NER/Glossary_NamedEntities_V3b_rev_Jan2022.ipynb): Python Jupyter notebook with test of the Spacy NER engine on the SE Glossary articles as stored in the KD. **Note**: the code was revised (January 2022) to load the data directly from the database and not from external files. 

4. [**/Spacy_NER/SE_NamedEntities_V3b_rev_Jan2022.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Content%20Database/Enrichment/Spacy_NER/SE_NamedEntities_V3b_rev_Jan2022.ipynb): This is the same algorithm as [3] but run on the scraped content from Statistics Explained articles. The input file is the one produced by scraping, with an additional column gathering all sections titles and contents. **Note**: the code was revised (January 2022) to load the data directly from the database and not from external files. 

5. [**/Gensim/Topic Modelling with Gensim_v6c_rev_Jan2022.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Content%20Database/Enrichment/Gensim/Topic%20Modelling%20with%20Gensim_v6c_rev_Jan2022.ipynb): Python Jupyter notebook with comprehensive topic modelling results, with the SE Glossary articles as stored in the KD. The algorithm uses Variational Bayes for inference. One cell contains the (disabled) code for an indicative grid search run. Do not comment-out the first line in this cell (%%script false --no-raise-error). **Note**: the code was revised (January 2022) to load the data directly from the database and not from external files. [**/Gensim/GC_Topic Modelling with Gensim_v6c_rev_Jan2022.ipynb**](https://github.com/eurostat/NLP4Stat/blob/testing/Content%20Database/Enrichment/Gensim/GC_Topic_Modelling_with_Gensim_v6c_rev_Jan2022.ipynb) is a Google Colab version.

 6. [**/Gensim/Topic Modelling with Gensim_v6c_SE_rev_Jan2022.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Content%20Database/Enrichment/Gensim/Topic%20Modelling%20with%20Gensim_v6c_SE_rev_Jan2022.ipynb): This is the same algorithm as [5] but run on the content from Statistics Explained articles (with different hyper-parameters). Again, do not comment-out the first command in the disabled cell (%%script false --no-raise-error) which contains an indicative grid search run. **Note**: the code was revised (January 2022) to load the data directly from the database and not from external files. [**/Gensim/GC_Topic_Modelling_with_Gensim_v6c_SE_rev_Jan2022.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Content%20Database/Enrichment/Gensim/GC_Topic_Modelling_with_Gensim_v6c_SE_rev_Jan2022.ipynb) is a Google Colab version.

 7. [**/SVOs/SVOs_extraction_v3_rev_Jan2022.ipynb**](https://github.com/eurostat/NLP4Stat/blob/main/Content%20Database/Enrichment/SVOs/SVOs_extraction_v3_rev_Jan2022.ipynb): A code which produces candidate Subject-Verb-Object triplets for the feeding of the KD. These involve a) Named Entities of many useful selected classes and b) the intersection of Categories related to SE articles and SE Glossary articles. The inputs are from both SE articles (titles, URLs, abstracts, context sections, full contents and related categories) and from SE Glossary entries (titles, URLs, definitions and related categories). Most of the information is used for debugging, but some elements such as URLs can also be used in Use Cases. Note that the code **takes a rather long time to run** (around 30' on a x64-i7-2.80GHz with 12GB RAM). **Note**: the code was revised (January 2022) to load the data directly from the database and not from external files.


