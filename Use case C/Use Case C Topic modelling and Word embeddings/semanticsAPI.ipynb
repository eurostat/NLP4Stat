{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"semanticsAPI.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install nltk==3.4 ## needs latest version\n","!pip install pyodbc\n","!apt-get install virtuoso-opensource\n","!pip install SPARQLWrapper\n","!pip install sparql_dataframe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MOf21a1l46oF","outputId":"2273f8ac-4ce1-4cf9-e987-d0f2cce0ca74","executionInfo":{"status":"ok","timestamp":1654509316238,"user_tz":-180,"elapsed":42842,"user":{"displayName":"Kimon Spiliopoulos","userId":"12668773501214850994"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nltk==3.4\n","  Downloading nltk-3.4.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4) (1.15.0)\n","Collecting singledispatch\n","  Downloading singledispatch-3.7.0-py2.py3-none-any.whl (9.2 kB)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4-py3-none-any.whl size=1436399 sha256=bc26b1bdaa016d4890942a3cbff507c842de52d73873b28f8a422d08e505ecf2\n","  Stored in directory: /root/.cache/pip/wheels/13/b8/81/2349be11dd144dc7b68ab983b58cd2fae353cdc50bbdeb09d0\n","Successfully built nltk\n","Installing collected packages: singledispatch, nltk\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed nltk-3.4 singledispatch-3.7.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyodbc\n","  Downloading pyodbc-4.0.32.tar.gz (280 kB)\n","\u001b[K     |████████████████████████████████| 280 kB 5.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyodbc\n","  Building wheel for pyodbc (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyodbc: filename=pyodbc-4.0.32-cp37-cp37m-linux_x86_64.whl size=287319 sha256=b0691d361e668e6cd7e1c34bbcfd64a786fd933827e9cc47b9f4b36190a1b43e\n","  Stored in directory: /root/.cache/pip/wheels/2e/9c/da/8652fd42e0f662015554f00a9e96fe4f438dfd1ef59787879e\n","Successfully built pyodbc\n","Installing collected packages: pyodbc\n","Successfully installed pyodbc-4.0.32\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libvirtodbc0 virtuoso-opensource-6.1 virtuoso-opensource-6.1-bin\n","  virtuoso-opensource-6.1-common virtuoso-server virtuoso-vad-conductor\n","  virtuoso-vsp-startpage\n","Suggested packages:\n","  virtuoso-vad-doc virtuoso-vad-demo virtuoso-vad-tutorial\n","  virtuoso-vad-rdfmappers virtuoso-vad-sparqldemo virtuoso-vad-syncml\n","  virtuoso-vad-bpel virtuoso-vad-isparql virtuoso-vad-ods virtuoso-vad-dbpedia\n","  virtuoso-vad-facetedbrowser\n","The following NEW packages will be installed:\n","  libvirtodbc0 virtuoso-opensource virtuoso-opensource-6.1\n","  virtuoso-opensource-6.1-bin virtuoso-opensource-6.1-common virtuoso-server\n","  virtuoso-vad-conductor virtuoso-vsp-startpage\n","0 upgraded, 8 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 4,835 kB of archives.\n","After this operation, 27.5 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtuoso-opensource-6.1-common amd64 6.1.6+repack-0ubuntu9 [45.0 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtuoso-opensource-6.1-bin amd64 6.1.6+repack-0ubuntu9 [2,831 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libvirtodbc0 amd64 6.1.6+repack-0ubuntu9 [259 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtuoso-opensource-6.1 amd64 6.1.6+repack-0ubuntu9 [163 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtuoso-opensource all 6.1.6+repack-0ubuntu9 [33.3 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtuoso-vad-conductor all 6.1.6+repack-0ubuntu9 [1,044 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtuoso-vsp-startpage all 6.1.6+repack-0ubuntu9 [428 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 virtuoso-server all 6.1.6+repack-0ubuntu9 [31.0 kB]\n","Fetched 4,835 kB in 1s (6,342 kB/s)\n","Preconfiguring packages ...\n","Selecting previously unselected package virtuoso-opensource-6.1-common.\n","(Reading database ... 155632 files and directories currently installed.)\n","Preparing to unpack .../0-virtuoso-opensource-6.1-common_6.1.6+repack-0ubuntu9_amd64.deb ...\n","Unpacking virtuoso-opensource-6.1-common (6.1.6+repack-0ubuntu9) ...\n","Selecting previously unselected package virtuoso-opensource-6.1-bin.\n","Preparing to unpack .../1-virtuoso-opensource-6.1-bin_6.1.6+repack-0ubuntu9_amd64.deb ...\n","Unpacking virtuoso-opensource-6.1-bin (6.1.6+repack-0ubuntu9) ...\n","Selecting previously unselected package libvirtodbc0.\n","Preparing to unpack .../2-libvirtodbc0_6.1.6+repack-0ubuntu9_amd64.deb ...\n","Unpacking libvirtodbc0 (6.1.6+repack-0ubuntu9) ...\n","Selecting previously unselected package virtuoso-opensource-6.1.\n","Preparing to unpack .../3-virtuoso-opensource-6.1_6.1.6+repack-0ubuntu9_amd64.deb ...\n","Unpacking virtuoso-opensource-6.1 (6.1.6+repack-0ubuntu9) ...\n","Selecting previously unselected package virtuoso-opensource.\n","Preparing to unpack .../4-virtuoso-opensource_6.1.6+repack-0ubuntu9_all.deb ...\n","Unpacking virtuoso-opensource (6.1.6+repack-0ubuntu9) ...\n","Selecting previously unselected package virtuoso-vad-conductor.\n","Preparing to unpack .../5-virtuoso-vad-conductor_6.1.6+repack-0ubuntu9_all.deb ...\n","Unpacking virtuoso-vad-conductor (6.1.6+repack-0ubuntu9) ...\n","Selecting previously unselected package virtuoso-vsp-startpage.\n","Preparing to unpack .../6-virtuoso-vsp-startpage_6.1.6+repack-0ubuntu9_all.deb ...\n","Unpacking virtuoso-vsp-startpage (6.1.6+repack-0ubuntu9) ...\n","Selecting previously unselected package virtuoso-server.\n","Preparing to unpack .../7-virtuoso-server_6.1.6+repack-0ubuntu9_all.deb ...\n","Unpacking virtuoso-server (6.1.6+repack-0ubuntu9) ...\n","Setting up virtuoso-opensource-6.1-bin (6.1.6+repack-0ubuntu9) ...\n","Setting up virtuoso-opensource-6.1-common (6.1.6+repack-0ubuntu9) ...\n","Setting up libvirtodbc0 (6.1.6+repack-0ubuntu9) ...\n","Setting up virtuoso-opensource-6.1 (6.1.6+repack-0ubuntu9) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Setting up virtuoso-opensource (6.1.6+repack-0ubuntu9) ...\n","Setting up virtuoso-server (6.1.6+repack-0ubuntu9) ...\n","Setting up virtuoso-vad-conductor (6.1.6+repack-0ubuntu9) ...\n","Setting up virtuoso-vsp-startpage (6.1.6+repack-0ubuntu9) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for systemd (237-3ubuntu10.53) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting SPARQLWrapper\n","  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n","Collecting rdflib>=6.1.1\n","  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n","\u001b[K     |████████████████████████████████| 482 kB 7.9 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (57.4.0)\n","Collecting isodate\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 536 kB/s \n","\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (3.0.9)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper) (4.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from isodate->rdflib>=6.1.1->SPARQLWrapper) (1.15.0)\n","Installing collected packages: isodate, rdflib, SPARQLWrapper\n","Successfully installed SPARQLWrapper-2.0.0 isodate-0.6.1 rdflib-6.1.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sparql_dataframe\n","  Downloading sparql_dataframe-0.4-py3-none-any.whl (3.5 kB)\n","Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from sparql_dataframe) (1.3.5)\n","Requirement already satisfied: SPARQLWrapper>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from sparql_dataframe) (2.0.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->sparql_dataframe) (1.21.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->sparql_dataframe) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.22.0->sparql_dataframe) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.22.0->sparql_dataframe) (1.15.0)\n","Requirement already satisfied: rdflib>=6.1.1 in /usr/local/lib/python3.7/dist-packages (from SPARQLWrapper>=1.8.1->sparql_dataframe) (6.1.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper>=1.8.1->sparql_dataframe) (57.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper>=1.8.1->sparql_dataframe) (4.11.4)\n","Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper>=1.8.1->sparql_dataframe) (0.6.1)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib>=6.1.1->SPARQLWrapper>=1.8.1->sparql_dataframe) (3.0.9)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper>=1.8.1->sparql_dataframe) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=6.1.1->SPARQLWrapper>=1.8.1->sparql_dataframe) (3.8.0)\n","Installing collected packages: sparql-dataframe\n","Successfully installed sparql-dataframe-0.4\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lYI_gObD0lem","outputId":"54cae796-40e5-4218-edd3-9c47c286d7cf","executionInfo":{"status":"ok","timestamp":1654509318750,"user_tz":-180,"elapsed":2521,"user":{"displayName":"Kimon Spiliopoulos","userId":"12668773501214850994"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["import requests\n","import os \n","import re\n","import logging\n","import sys\n","import pyodbc\n","import hashlib\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","from SPARQLWrapper import SPARQLWrapper, POST, DIGEST, GET\n","from SPARQLWrapper import JSON, INSERT, DELETE\n","import sparql_dataframe\n","import nltk\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import wordnet as wn\n","from nltk.corpus import wordnet as wn\n","import nltk\n","nltk.download('wordnet')\n","\n"]},{"cell_type":"code","source":["def Remove(duplicate):\n","    final = []\n","    for num in duplicate:\n","        if num not in final:\n","            final.append(num)\n","    return final"],"metadata":{"id":"14sFGrY412M-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def wordNet(word):\n","  keyword = word.split(\" \")\n","\n","  listWN = []\n","  for key in keyword:\n","    listKeyword = []\n","    synonyms = wn.synsets(key)\n","    for s in synonyms:\n","      helper = s.name().replace(\".n.\", \"\").replace(\".v.\", \"\").replace(\".r.\", \"\").replace(\".a.\", \"\")\n","      result = ''.join([i for i in helper if not i.isdigit()])\n","      if result not in keyword:\n","        syn1 = wn.synsets(key)[0]\n","        syn2 = wn.synsets(result)[0]\n","        score = syn1.wup_similarity(syn2)\n","        listKeyword.append((result, score))\n","    listWN.append((key, listKeyword))\n","\n","  finalListWN =[]\n","  for l in listWN:\n","    finalListWN.append((l[0], Remove(l[1])))\n","\n","\n","  return finalListWN"],"metadata":{"id":"pVQNd2Q01wFo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class findSimilarity():\n","\n","    def __init__(self, entities, properties, perceived, weights):\n","        self.entities = entities\n","        self.properties = properties\n","        self.perceived = perceived\n","        self.weights = weights\n","        \n","    def Remove(self, duplicate):\n","        final = []\n","        for num in duplicate:\n","            if num not in final:\n","                final.append(num)\n","        return final\n","\n","    def hasNumbers(self, inputString):\n","        return any(char.isdigit() for char in inputString)\n","\n","    def cleaning_entities(self):\n","        list1 = []\n","        entity_property, second_cleaning = {}, []\n","        for i in range(len(self.entities)):\n","            first_cleaning = self.entities[i].replace('/a/[', '').replace(']', '')\n","            for j in range(len(self.properties)):\n","                if self.properties[j] + '/' in first_cleaning:\n","                    second_cleaning = first_cleaning.replace(self.properties[j] + '/', '').replace(',', '')\n","                    if entity_property.get(self.properties[j]) == None:\n","                        entity_property.setdefault(self.properties[j], []).append(second_cleaning)\n","                    else:\n","                        entity_property[self.properties[j]].append(second_cleaning)\n","                    break\n","            list1.append((second_cleaning, self.weights[i]))\n","\n","\n","        wanted_properties = [\"/r/RelatedTo\"]\n","\n","        list_key_help = []\n","        for key in entity_property.keys():\n","            if key in wanted_properties:\n","                list_key_help.append(key)\n","\n","        entity_property_keep = {}\n","        for property in wanted_properties:\n","            if property in list_key_help:\n","                entity_property_keep[property] = entity_property[property]\n","            else:\n","                entity_property_keep[property] = []\n","\n","\n","        return list1, entity_property_keep\n","\n","    def cleaning_entities2(self, entities_observed, perceived_weights):\n","\n","        for observed in entities_observed:\n","            for entity in range(len(entities_observed[observed]) - 1, -1, -1):\n","                if not (entities_observed[observed][entity].count(\"/en/\") == 2):\n","                    del entities_observed[observed][entity]\n","                else:\n","                    for perceived_entity in self.perceived:\n","                        if (('/c/en/' + perceived_entity + '/') in entities_observed[observed][entity]):\n","                            entities_observed[observed][entity] = entities_observed[observed][entity].replace(\n","                                '/c/en/' + perceived_entity + '/', '')\n","                        if (('/c/en' + perceived_entity + '/n/') in entities_observed[observed][entity]):\n","                            entities_observed[observed][entity] = entities_observed[observed][entity].replace(\n","                                '/c/en/' + perceived_entity + '/n/', '')\n","\n","        for observed in entities_observed:\n","            annotator = 0\n","            for i in entities_observed[observed]:\n","                if ('wn/' in i):\n","                    entities_observed[observed][annotator] = entities_observed[observed][annotator].replace('wn/', '_')\n","                if ('/n/' in i):\n","                    entities_observed[observed][annotator] = entities_observed[observed][annotator].replace('/n/', '')\n","                if ('/v/' in i):\n","                    entities_observed[observed][annotator] = entities_observed[observed][annotator].replace('/v/', '')\n","                if ('/a/' in i):\n","                    entities_observed[observed][annotator] = entities_observed[observed][annotator].replace('/a/', '')\n","                if ('/c/en/' in i):\n","                    entities_observed[observed][annotator] = entities_observed[observed][annotator].replace('/c/en/',\n","                                                                                                            '')\n","                if ('n/' in i):\n","                    entities_observed[observed][annotator] = entities_observed[observed][annotator].replace('n/', '')\n","                if ('/' in i):\n","                    entities_observed[observed][annotator] = entities_observed[observed][annotator].replace('/', '')\n","                annotator += 1\n","\n","        for observed in entities_observed:\n","            entities_observed[observed] = self.Remove(entities_observed[observed])\n","            for i in entities_observed[observed]:\n","                if self.hasNumbers(i) == True:\n","                    entities_observed[observed].remove(i)\n","\n","        helper_list_weights = []\n","        for property in entities_observed:\n","            for entity in entities_observed[property]:\n","                helper_list_weights.append(entity)\n","\n","        list_with_weights = []\n","        for entity in helper_list_weights:\n","            for weight in perceived_weights:\n","                if entity in weight[0]:\n","                    list_with_weights.append((entity, weight[1]))\n","\n","        return entities_observed, list_with_weights\n","\n","    def grounding(self, cleaned_entities, weigths_of_entities):\n","        porter = PorterStemmer()\n","        weigths_of_entities = self.Remove(weigths_of_entities)\n","        helperWeights = []\n","        for w in weigths_of_entities:\n","          if w[1] == 1.0 and \"_\" not in w[0] and str(w[0]) != str(self.perceived[0]):\n","              helperWeights.append((w[0], w[1]))\n","        \n","        helperWeights = self.Remove(helperWeights)\n","        helperNew = []\n","        for h in helperWeights:\n","            syn = wn.synsets(str(h[0]))\n","            if len(syn) > 1:\n","                helperNew.append(h)\n","                \n","        return helperNew "],"metadata":{"id":"DtMnHDtN4yuF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def myfunc(term):\n","    return 'http://api.conceptnet.io/c/en/' + term + '?offset=0&limit=1000'\n","\n","\n","def helperCN(c):\n","\n","    id = myfunc(c)\n","    respone = requests.get(id)\n","    objAction = respone.json()\n","    lst1 = [relation['rel']['@id'] for relation in objAction['edges']]\n","    lst2 = [relation['@id'] for relation in objAction['edges']]\n","    lst3 = [relation['weight'] for relation in objAction['edges']]\n","\n","    return lst1, lst2, lst3"],"metadata":{"id":"_tDHQ6S96cyh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conceptNet(word):\n","  keyword = word.split(\" \")\n","  listWord = []\n","  for t in keyword:\n","    cleaned_weights, allData = [], []\n","    data1, data2, data3 = helperCN(t)\n","    prp = findSimilarity(data2, data1, [t], data3)\n","    first = prp.cleaning_entities()\n","    second, weights = prp.cleaning_entities2(first[1], first[0])\n","    cleaned_weights = prp.grounding(second, weights)\n","    listWord.append((t,cleaned_weights[:3]))\n","\n","  listWord = Remove(listWord)\n","  return listWord\n"],"metadata":{"id":"gObroD0S6h4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#recommendationWN = wordNet('meat beef bike')##given a string, each word must be seperated by a space, it will then return the synonyms and the similarity score from wordnet for each word\n","#print(recommendationWN)\n","#recommendationCN = conceptNet('meat beef bike')##given a string, each word must be seperated by a space, it will then return the synonyms and the similarity score from conceptnet for each word, I have restricted it to 1.0 (top recommendations) otherwise there is to much noise\n","#print(recommendationCN)"],"metadata":{"id":"QnE7Cjie1zd2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nltk.download('stopwords')\n","\n","def simpleCN_list2(terms, threshold):\n","    objects = [requests.get('http://api.conceptnet.io/related/c/en/'+t+'?filter=/c/en').json() for t in terms]\n","    llist = [[re.sub('/c/en/','',rel['@id']).split('_')for rel in obj['related'] if rel['weight'] > threshold] for obj in objects]\n","\n","    llist = [elem for sublist in llist for ind_list in sublist for elem in ind_list if elem not in stopwords.words('english') and elem not in terms ]\n","    return llist"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5hUAqru2WyAv","outputId":"348521b3-540b-4397-e301-9242d6a5807f","executionInfo":{"status":"ok","timestamp":1654509319011,"user_tz":-180,"elapsed":11,"user":{"displayName":"Kimon Spiliopoulos","userId":"12668773501214850994"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]}]}