{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDAl1L9iXEVQ"
   },
   "source": [
    "# Note: Please run all cells once. When the widgets are ready for use, the notebook will automatically will hide all code chunks and ... voila!!! #\n",
    "***\n",
    "\n",
    "*    For the setup of the Virtuoso ODBC data source please see section 1a in https://github.com/eurostat/NLP4Stat/tree/testing/Software%20Environment\n",     
    "*    Download the notebook as \"raw\" file and save it with extension .ipynb (cut the .txt extension which is added)\n",
    "*    Install the necessary libraries from your jupyter command prompt. These, together with the versions used, are:\n",
    "    *    tqdm==4.62.3\n",
    "    *    spacy==3.0.7\n",
    "    *    seaborn==0.11.2\n",
    "    *    scispacy==0.4.0\n",
    "    *    pandas==1.3.5\n",
    "    *    numpy==1.20.3\n",
    "    *    matplotlib==3.4.3\n",
    "    *    joblib==1.1.0\n",
    "    *    ipywidgets==7.6.5\n",
    "    *    if you have difficulties installing scispacy install first numpy and nmslib\n",
    "\n",
    "*   Copy the input files: **data.csv**, **tm_topics.csv**, **df_topic_sents_keywords.csv**, **SVOs_all_5_24_17_37.xlsx** from the [notebook folder](https://github.com/eurostat/NLP4Stat/tree/testing/Use%20case%20A/Use%20Case%20A%20Widgets%20Demo) to the same folder where you downloaded the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 4,
        "row": 0,
        "width": 12
       }
      }
     }
    },
    "id": "b749kSQbXgd3"
   },
   "source": [
    "# Use case A \n",
    "### “Asset querying” – Making the most of internal data assets in their multiple forms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 4,
        "width": 12
       }
      }
     }
    },
    "id": "jMNe51AXXgd4"
   },
   "source": [
    "The Use Case A is the ability to annotate and enrich content from the Knowledge Database.\n",
    "A user makes a query to the Eurostat Website, this query goes through a tool that is in direct relation with KDB. The KDB is used to enriched documents from the Eurostat Website, and the product of these enrich documents will be the answer to the query made by the user. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 7,
        "width": 12
       }
      }
     }
    },
    "id": "ZWsTozcSXgd6"
   },
   "source": [
    "The query made by the user will either be a query builder, a faceted search, a data exploration or a visual data browsing. As presented in the schema above, the two first solutions, query builders and faceted search are about looking into specific content, while the two latter, data exploration and visual data browsing (graphical navigation) are more used to provide a general idea of the content inside the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 13,
        "width": 12
       }
      }
     }
    },
    "id": "zGT0avmoXgd9"
   },
   "source": [
    "### Scenario A: Query Builder\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 2,
        "row": 16,
        "width": 12
       }
      }
     }
    },
    "id": "RKVHEXL_Xgd-"
   },
   "source": [
    "A query builder is a program that builds a query from a set of parameters designed to perform a search in a specific database.I the libraries are loaded and the data related to the statistical articles are uploaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8ibNWPOKXEVe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.0.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl (47.1 MB)\n",
      "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from en-core-web-md==3.0.0) (3.0.7)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.13)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (21.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.20.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.2)\n",
      "Requirement already satisfied: setuptools in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (58.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.26.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in d:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\kimon\\appdata\\roaming\\python\\python39\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.4.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.1.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "Finished loading.\n"
     ]
    }
   ],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import numpy as np \n",
    "import os\n",
    "##import ee\n",
    "##import string \n",
    "\n",
    "#Widgets libraries\n",
    "\n",
    "import ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact,Layout, IntSlider, interactive, widgets, interact_manual,HBox,fixed,VBox, Box, HTML\n",
    "from ipywidgets import Button, FloatText, Textarea, Dropdown, Label\n",
    "from ipywidgets import interact_manual\n",
    "layout = widgets.Layout(width='400px', height='30px')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "pd.set_option('display.max_rows' , 1000)\n",
    "pd.set_option('display.max_columns' , 1000)\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "##from sklearn.feature_extraction import text\n",
    "##from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "##from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import scispacy\n",
    "#import spacy\n",
    "#import en_core_sci_lg\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "from IPython.display import HTML, display,clear_output\n",
    "from IPython.utils import io\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#from os.path import isfile\n",
    "from itertools import product\n",
    "import re\n",
    "import pprint\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import sys\n",
    "## Run to install the language library, then comment-out\n",
    "!{sys.executable} -m spacy download en_core_web_md\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "print('Finished loading.')\n",
    "nlp.max_length = 3000000\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 5,
        "row": 18,
        "width": 12
       }
      }
     }
    },
    "id": "yOnzuKEUXgeA"
   },
   "source": [
    "#### **Builder 1: Simple Keyword Searching**\n",
    "***\n",
    "The user inserts a keyword and this query structure finds articles including the keyword in the raw content of the article and then it returns the titles of the articles (related to the keyword) with their urls.\n",
    "\n",
    "We have created an interactive widget, where the user has the potential to change simultaneously the keyword, category and number of articles displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gyQOHkiGXEVk"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')   \n",
    "##data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "CpnpmFPYXgeD"
   },
   "outputs": [],
   "source": [
    "def change_top_articles(Top_articles, Keywords, categories):\n",
    "  \n",
    " \n",
    "  #Search by category in raw content\n",
    "  if Keywords == '':\n",
    "    print(\"\")\n",
    "  else:\n",
    "    if categories == \"All Categories\":\n",
    "      df1 = data[data['raw content'].str.contains(Keywords)]\n",
    "      if df1.title.count() == 0:\n",
    "        print(\"Not matches found\")\n",
    "      else:\n",
    "        print(df1.title.count(),\" articles found\")\n",
    "        #output  \n",
    "        h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "        return display(HTML( h))\n",
    "        #print(df1[:Top_articles.value])\n",
    "    \n",
    "     \n",
    "    else:\n",
    "      candidate = data[data['categories'].str.contains(categories)]\n",
    "      df1 = candidate[candidate['raw content'].str.contains(Keywords)]\n",
    "      if df1.title.count() == 0:\n",
    "        print(\"Not mathces found\")\n",
    "      else:\n",
    "        print(df1.title.count(),\" articles found\")\n",
    "        #print(df1[:Top_articles.value])\n",
    "        #output  \n",
    "        h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "        return display(HTML( h))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "dcqB4zq_XgeD"
   },
   "outputs": [],
   "source": [
    "def query_build2():\n",
    "  style = {'description_width': 'initial'}\n",
    "  categories = widgets.Dropdown(\n",
    "      description='Select Category:',\n",
    "      options=['All Categories','Health', 'Tourism',  'Energy', 'Agriculture', 'World trade' ],\n",
    "      value='All Categories',\n",
    "      style=style\n",
    "  )\n",
    "\n",
    "  Top_articles = widgets.IntSlider(\n",
    "      description='Display',\n",
    "      tooltip='maximum:',\n",
    "      value=5,\n",
    "      min=1, \n",
    "      max = 30,\n",
    "      style={'description_width': 'initial'}\n",
    "  )\n",
    "\n",
    "\n",
    "  Keywords = widgets.Text(\n",
    "      value='hospitals',\n",
    "      placeholder='Type something',\n",
    "      description='Keywords:',\n",
    "      disabled=False\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  ui = widgets.HBox([Keywords, categories, Top_articles])\n",
    "\n",
    "  out = widgets.interactive_output(change_top_articles, {'Top_articles': Top_articles, 'Keywords': Keywords, 'categories': categories})\n",
    "\n",
    "  display(ui, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 4,
        "row": 23,
        "width": 12
       }
      }
     }
    },
    "id": "EhkwCMvoXgeE"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606170caa6e347d1a9304ea62ee9c694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='hospitals', description='Keywords:', placeholder='Type something'), Dropdown(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480ebef62641483b99d70bf12d2a7a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_build2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 5,
        "row": 27,
        "width": 12
       }
      }
     }
    },
    "id": "QbbPP1uOXgeE"
   },
   "source": [
    "#### **Builder 2: Advanced Keyword Searching**\n",
    "***\n",
    "This query structure allows for advanced searching in terms of searching options. For example, the user can either search by titles, keywords related to the abstract or to the content of the article. An individual could also narrow down results by selecting a spesific category, year of the last update of the article and finally how many articles to display.\n",
    "\n",
    "We have created an interctive widget, where the user can shift from simple keyword searching (described in Builder 1)  to the advanced mode. There is still the potential for the user to change simultaneously the searching options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "AqiB0eAQNqZg"
   },
   "outputs": [],
   "source": [
    "def AdvancedSearch(Top_articles, Keywords, categories, title, abstract):\n",
    "  #data = dat\n",
    "  # Search by Title\n",
    "  if title == '':\n",
    "    # Abstract if\n",
    "    if abstract == '':\n",
    "      # Keyword if\n",
    "      if Keywords == '':\n",
    "        print(\"\")\n",
    "\n",
    "      # Keywords == string\n",
    "      else:\n",
    "        if categories == \"All Categories\":\n",
    "          df1 = data[data['raw content'].str.contains(Keywords)]\n",
    "          if df1.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(df1.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "            #print(df1[:Top_articles.value])\n",
    "        \n",
    "        #Else for category = 'string'\n",
    "        else:\n",
    "          candidate = data[data['categories'].str.contains(categories)]\n",
    "          df1 = candidate[candidate['raw content'].str.contains(Keywords)]\n",
    "          if df1.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(df1.title.count(),\" articles found\")\n",
    "            #print(df1[:Top_articles.value])\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Else abstract ==string\n",
    "    else:\n",
    "      abstractArt = data[data['abstract'].str.contains(abstract)]\n",
    "\n",
    "      #Keywords if\n",
    "      if Keywords == '':\n",
    "        if categories == \"All Categories\":\n",
    "          \n",
    "          if abstractArt.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(abstractArt.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in abstractArt[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "            \n",
    "        \n",
    "        #Else for category = 'string'\n",
    "        else:\n",
    "          candidate = abstractArt[abstractArt['categories'].str.contains(categories)]\n",
    "          if candidate.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(candidate.title.count(),\" articles found\")\n",
    "            #print(df1[:Top_articles.value])\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in candidate[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "\n",
    "\n",
    "      # else keywords == string\n",
    "      else:\n",
    "        KeywordArt = abstractArt[abstractArt['raw content'].str.contains(Keywords)]\n",
    "        if categories == \"All Categories\":\n",
    "            if KeywordArt.title.count() == 0:\n",
    "              print(\"Not mathces found\")\n",
    "            else:\n",
    "              print(KeywordArt.title.count(),\" articles found\")\n",
    "              #output  \n",
    "              h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in KeywordArt[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "              return display(HTML( h))\n",
    "              \n",
    "        else:\n",
    "          candidate = KeywordArt[KeywordArt['categories'].str.contains(categories)]\n",
    "          if candidate.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(candidate.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in candidate[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "\n",
    "    \n",
    "    \n",
    " \n",
    " ################ Else for title = 'string' #######################################################################################################\n",
    "  else:\n",
    "    #Abstract if \n",
    "    titleArt = data[data['title'].str.contains(title)]\n",
    "    if abstract == '':\n",
    "      # Keyword is\n",
    "      if Keywords == '':\n",
    "        if categories == \"All Categories\":\n",
    "          if titleArt.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(titleArt.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in titleArt[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "            \n",
    "        else:\n",
    "          candidate = titleArt[titleArt['categories'].str.contains(categories)]\n",
    "          df1 = candidate[candidate['title'].str.contains(title)]\n",
    "          if df1.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(df1.title.count(),\" articles found\")\n",
    "            #print(df1[:Top_articles.value])\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "\n",
    "      # Keyword == string\n",
    "      else:\n",
    "        KeywordArt = titleArt[titleArt['raw content'].str.contains(Keywords)]\n",
    "        if categories == \"All Categories\":\n",
    "          if KeywordArt.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(KeywordArt.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in KeywordArt[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "            \n",
    "        else:\n",
    "          candidate = KeywordArt[KeywordArt['categories'].str.contains(categories)]\n",
    "          df1 = candidate[candidate['title'].str.contains(title)]\n",
    "          if df1.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(df1.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "\n",
    "\n",
    "\n",
    "    #else Abstract == string  \n",
    "    else:\n",
    "      abstractArt = titleArt[titleArt['abstract'].str.contains(abstract)]\n",
    "      # Keyword if\n",
    "      if Keywords == '':\n",
    "        if categories == \"All Categories\":\n",
    "          \n",
    "          if abstractArt.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(abstractArt.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in abstractArt[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "            \n",
    "        else:\n",
    "          candidate = abstractArt[abstractArt['categories'].str.contains(categories)]\n",
    "          df1 = candidate[candidate['title'].str.contains(title)]\n",
    "          if df1.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(df1.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      # Else Keyword == string\n",
    "      else:\n",
    "        KeywordArt = abstractArt[abstractArt['raw content'].str.contains(Keywords)]\n",
    "        if categories == \"All Categories\":\n",
    "          \n",
    "          if KeywordArt.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(KeywordArt.title.count(),\" articles found\")\n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in KeywordArt[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n",
    "            \n",
    "        else:\n",
    "          candidate = KeywordArt[KeywordArt['categories'].str.contains(categories)]\n",
    "          df1 = candidate[candidate['title'].str.contains(title)]\n",
    "          if df1.title.count() == 0:\n",
    "            print(\"Not mathces found\")\n",
    "          else:\n",
    "            print(df1.title.count(),\" articles found\")\n",
    "            \n",
    "            #output  \n",
    "            h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in df1[[\"url\",\"title\"]][0:Top_articles].values])\n",
    "            return display(HTML( h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "_xZpGKGrFyA4"
   },
   "outputs": [],
   "source": [
    "def query_build4():\n",
    "  style = {'description_width': 'initial'}\n",
    " \n",
    "  categories = widgets.Dropdown(\n",
    "      description='',\n",
    "      options=['All Categories','Health', 'Tourism',  'Energy', 'Agriculture', 'World trade' ],\n",
    "      value='All Categories',\n",
    "      style=style\n",
    "  )\n",
    "\n",
    "  Top_articles = widgets.IntSlider(\n",
    "      description='Display:',\n",
    "      tooltip='maximum:',\n",
    "      value=5,\n",
    "      min=1, \n",
    "      max = 30,\n",
    "      style=style\n",
    "  )\n",
    "  Top_articles.style.handle_color = 'lightblue'\n",
    "\n",
    "\n",
    "  Pick_dat = widgets.IntRangeSlider(\n",
    "      description=' ',\n",
    "      tooltip='maximum:',\n",
    "      value=[2010,2020],\n",
    "      min=1950, \n",
    "      max = 2021,\n",
    "      style=style\n",
    "  )\n",
    "\n",
    "  \n",
    "  Pick_dat.style.handle_color = 'lightblue'\n",
    "\n",
    "  Search_byTitle = widgets.Text(\n",
    "      value='',\n",
    "      placeholder='Type something',\n",
    "      description='',\n",
    "      disabled=False\n",
    "  )\n",
    "\n",
    "  Search_byAbstract = widgets.Text(\n",
    "      value='',\n",
    "      placeholder='Type something',\n",
    "      description='',\n",
    "      disabled=False\n",
    "  )\n",
    "\n",
    "  Keywords = widgets.Text(\n",
    "      value='hospitals',\n",
    "      placeholder='Type something',\n",
    "      description=' ',\n",
    "      disabled=False\n",
    "  )\n",
    "\n",
    "  form_item_layout = Layout(justify_content='space-between')\n",
    "\n",
    "  form_items = [\n",
    "      HBox([Label(value='Search by Title:'), Search_byTitle], layout=form_item_layout),\n",
    "      HBox([Label(value='Search in Abstract'), \n",
    "          Search_byAbstract], layout=form_item_layout),\n",
    "      HBox([Label(value='Keywords'),Keywords], layout=form_item_layout),\n",
    "      HBox([Label(value='Categories'), \n",
    "          categories], layout=form_item_layout),\n",
    "      HBox([Label(value='Year'), \n",
    "          Pick_dat], layout=form_item_layout)\n",
    "  ]\n",
    "\n",
    "  form = VBox(form_items, layout=Layout(\n",
    "      border='2px solid gray', padding='10px',\n",
    "      align_items='stretch', width='65%')\n",
    "  )\n",
    "\n",
    "  box2 = widgets.HBox([Top_articles])\n",
    "\n",
    "  out = widgets.interactive_output(AdvancedSearch, {'Top_articles': Top_articles, 'Keywords': Keywords, 'categories': categories, 'title':Search_byTitle, 'abstract':Search_byAbstract})\n",
    "\n",
    "  return display(form, box2, out)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "3i3DNsquEu7G"
   },
   "outputs": [],
   "source": [
    "def builder_Advanced():\n",
    "  output = widgets.Output()\n",
    "  style = {'description_width': 'initial'}\n",
    "  advanced_search = widgets.Button(\n",
    "      description='Advanced search',\n",
    "      button_style='primary',\n",
    "      tooltip='Click to download article',\n",
    "      disabled=False,\n",
    "      style=style )\n",
    "  \n",
    "  minimize = widgets.Button(\n",
    "    description='Minimize',\n",
    "    button_style='primary',\n",
    "    tooltip='Minimize',\n",
    "    disabled=False,\n",
    "    style=style)\n",
    "  display ( query_build2(),widgets.HBox([advanced_search]))\n",
    "  \n",
    " \n",
    "  def on_search_clicked(b):\n",
    "    clear_output()  \n",
    "    #call a function a function for getting advanced searching options\n",
    "    display ( query_build4(),widgets.HBox([minimize]))  \n",
    "  advanced_search.on_click(on_search_clicked)  \n",
    "\n",
    "  def on_minimize_clicked(b):\n",
    "    clear_output() \n",
    "    display ( query_build2(),widgets.HBox([advanced_search]))\n",
    "\n",
    "  minimize.on_click(on_minimize_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 6,
        "row": 32,
        "width": 12
       }
      }
     }
    },
    "id": "a4C0MXAiFI9o"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff655e6328348fab4c88dc22e5d0558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='hospitals', description='Keywords:', placeholder='Type something'), Dropdown(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3460fa6ee8f4d5482660077a93cdbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270b5eab9c6d41c89092a630a3e75b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Advanced search', style=ButtonStyle(), tooltip='Cli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder_Advanced()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 38,
        "width": 12
       }
      }
     }
    },
    "id": "cui5CvxSXgeF"
   },
   "source": [
    "### Scenario B: Facets\n",
    "***\n",
    "\n",
    "For this case scenario, we have implemented some query structures based on topic modelling and semantic analysis (Name Entity Recognition and their correspondive relations).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 5,
        "row": 41,
        "width": 12
       }
      }
     }
    },
    "id": "Ds9hctqy0VRl"
   },
   "source": [
    "#### **Topic Modelling - Related Articles**\n",
    "***\n",
    "This query scenario is based on datasets extracted by Topic Modelling with Gensim library. In particular, user has the potential to search articles according to the dominant topics, narrow down results by typing topic keywords or even to find related articles to topic keywords that are not necessarily articles of the selected dominant topic. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "xgtdkCyMXgeI"
   },
   "outputs": [],
   "source": [
    "tm_topics = pd.read_csv('tm_topics.csv')\n",
    "df_topic_sents_keywords = pd.read_csv('df_topic_sents_keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "g1NIQf2OXgeI"
   },
   "outputs": [],
   "source": [
    "def display_side_by_side(dfs:list, captions:list):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "VsqfMBdiXgeJ"
   },
   "outputs": [],
   "source": [
    "def get_Related_Articles(selector,keyword,cloud):\n",
    "  topics = tm_topics[tm_topics['Topic name'].str.contains(selector)]\n",
    "  topicID = topics['Topic id'].values.tolist()\n",
    "  if cloud:\n",
    "    for i in topicID:\n",
    "      candidateArticles = df_topic_sents_keywords[df_topic_sents_keywords['Dominant_Topic']== i]\n",
    "      keywordArticles = df_topic_sents_keywords[df_topic_sents_keywords['Topic_Keywords'].str.contains(keyword)]\n",
    "      related = keywordArticles.drop(keywordArticles[keywordArticles['Dominant_Topic']==i].index)\n",
    "      #display_side_by_side([df1, df2, df3], ['caption1', 'caption2', 'caption3'])\n",
    "    return display_side_by_side([candidateArticles[['Text title']],related[['Text title']]], ['Articles on dominant topic selected', 'Articles related to keyword'])\n",
    "\n",
    "  else:\n",
    "    if keyword == '':\n",
    "      for i in topicID:\n",
    "        candidateArticles = df_topic_sents_keywords[df_topic_sents_keywords['Dominant_Topic']== i]\n",
    "      return display(candidateArticles[['Text title']])\n",
    "\n",
    "    else:\n",
    "      for i in topicID:\n",
    "        candidateArticles = df_topic_sents_keywords[df_topic_sents_keywords['Dominant_Topic']== i]\n",
    "        #candidateArticles = df_topic_sents_keywords[df_topic_sents_keywords['Topic_Keywords'].str.contains(keyword)]\n",
    "      return display(candidateArticles[['Text title']])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "XQ7yi2HxXgeJ"
   },
   "outputs": [],
   "source": [
    "def ShowRelatedArticles():\n",
    "  style = {'description_width': 'initial'}\n",
    "\n",
    "  selector =  widgets.Combobox(\n",
    "  placeholder='Choose a Title',\n",
    "  options=list(tm_topics['Topic name'].unique())+['All'],\n",
    "  description='Select topic')\n",
    " \n",
    "\n",
    "  cloud = widgets.Checkbox(\n",
    "      value=False,\n",
    "      description='Show related articles',\n",
    "      style=style\n",
    "  )\n",
    "  \n",
    "  Keywords = widgets.Text(\n",
    "      value='',\n",
    "      placeholder='Type something',\n",
    "      description='Keywords:',\n",
    "      disabled=False\n",
    "  )\n",
    "  ui  = widgets.HBox([selector, Keywords ,cloud]) \n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "  out = widgets.interactive_output(get_Related_Articles, {'selector':selector,'keyword': Keywords, 'cloud':cloud})\n",
    "\n",
    "  display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 9,
        "row": 47,
        "width": 7
       }
      }
     }
    },
    "id": "YineHbidXgeJ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964c82c7a0e64964856226cbadfff3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Combobox(value='', description='Select topic', options=('Technological product and process inno…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a24fa08a51c4150965aefd521d1d2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ShowRelatedArticles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 5,
        "row": 71,
        "width": 12
       }
      }
     }
    },
    "id": "HAKNbgwTXgeL"
   },
   "source": [
    "####  **Named-Entity Recognition methods**\n",
    "***\n",
    "This query structure relies on Subject-Verb-Object triplets extracted for both Statistics Explained and Glossary articles. \n",
    "\n",
    "We have implemented 3 subcases. In all cases, the difference is on text box selection options. \n",
    "\n",
    "The user types keywords, and instantly proposing phrases are returned along with a list of articles. Also there is an option to display only either statistics explained or glossary articles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 76,
        "width": 12
       }
      }
     }
    },
    "id": "xF1FBnsw5SSF"
   },
   "source": [
    "***\n",
    "##### Case 1: Proposing phrases - whole sentences containing at least one typed keyword\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "8SFdF6F0XgeL"
   },
   "outputs": [],
   "source": [
    "ner = pd.read_excel('SVOs_all_5_24_17_37.xlsx')\n",
    "ner['SVOs_together'] = ner['Subject'] + ' ' + ner['Verb'] + ' ' + ner['Object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "cb9dRjocAFxS"
   },
   "outputs": [],
   "source": [
    "def NER_articles1(selector,Statistics_Explained,Glossaries,howmany):\n",
    "  # If Statistics_Explained == True, then show only Statistics Explained Articles\n",
    "  if Statistics_Explained:\n",
    "    candidateArticles = ner[ner['Sentence'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('SE')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "  \n",
    "  # If Glossaries == True, then show only Glossary articles\n",
    "  elif Glossaries:\n",
    "    candidateArticles = ner[ner['Sentence'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('GL')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "  \n",
    "  elif Statistics_Explained & Glossaries:\n",
    "    Statistics_Explained = False\n",
    "    candidateArticles = ner[ner['Sentence'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('GL')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "\n",
    "\n",
    "  else:\n",
    "    candidateArticles = ner[ner['Sentence'].str.contains(selector)]\n",
    "    candidateArticles = candidateArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    print(candidateArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in candidateArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "zyEUer5u-OvS"
   },
   "outputs": [],
   "source": [
    "def NER_builder1():\n",
    "  style = {'description_width': 'initial'}\n",
    "\n",
    "  selector =  widgets.Combobox(\n",
    "    placeholder='Type something, e.g., EU, ASEA etc.',\n",
    "    options=list(ner['Sentence'].unique()),\n",
    "    description='Search')\n",
    "  \n",
    "  Statistics_Explained = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Only Statistics Explained',\n",
    "    style=style)\n",
    "  \n",
    "  Glossaries = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Only Glossaries',\n",
    "    style=style)\n",
    "  \n",
    "  howmany = widgets.IntSlider(\n",
    "    description='Display:',\n",
    "    tooltip='maximum:',\n",
    "    value=5,\n",
    "    min=1, \n",
    "    max = 30,\n",
    "    style=style )\n",
    "  howmany.style.handle_color = 'lightblue'\n",
    "  \n",
    "  ui = widgets.HBox([selector,Statistics_Explained,Glossaries, howmany])\n",
    "  out = widgets.interactive_output(NER_articles1, {'selector':selector,'Statistics_Explained': Statistics_Explained, 'Glossaries':Glossaries, 'howmany':howmany})\n",
    "\n",
    "\n",
    "  display(ui,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 7,
        "row": 79,
        "width": 12
       }
      }
     }
    },
    "id": "rJWU94mY_GPN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e482480424476afc143cfb711296a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Combobox(value='', description='Search', options=('This vision was confirmed by a Council Recom…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4106dbdaa43c4b5184396e48c96670d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NER_builder1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 86,
        "width": 12
       }
      }
     }
    },
    "id": "BP4v9aT98cp8"
   },
   "source": [
    "***\n",
    "##### Case 2: Proposing organizations, countries, etc., instead of phrases\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "WI4vq8Csu097"
   },
   "outputs": [],
   "source": [
    "def NER_articles2(selector,Statistics_Explained,Glossaries,howmany):\n",
    "  # If Statistics_Explained == True, then show only Statistics Explained Articles\n",
    "  if Statistics_Explained:\n",
    "    candidateArticles = ner[ner['Key'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('SE')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "  # If Glossaries == True, then show only Glossary articles\n",
    "  elif Glossaries:\n",
    "    candidateArticles = ner[ner['Key'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('GL')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "  \n",
    "  elif Statistics_Explained & Glossaries:\n",
    "    Statistics_Explained = False\n",
    "    candidateArticles = ner[ner['Key'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('GL')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "\n",
    "\n",
    "  else:\n",
    "    candidateArticles = ner[ner['Key'].str.contains(selector)]\n",
    "    candidateArticles = candidateArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    print(candidateArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in candidateArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "9fg3AnAEuJcu"
   },
   "outputs": [],
   "source": [
    "def NER_builder2():\n",
    "  style = {'description_width': 'initial'}\n",
    "\n",
    "  selector =  widgets.Combobox(\n",
    "    placeholder='Type something, e.g., EU, ASEA etc.',\n",
    "    options=list(ner['Key'].unique()),\n",
    "    description='Search')\n",
    "  \n",
    "  Statistics_Explained = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Only Statistics Explained',\n",
    "    style=style)\n",
    "  \n",
    "  Glossaries = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Only Glossaries',\n",
    "    style=style)\n",
    "  \n",
    "  howmany = widgets.IntSlider(\n",
    "    description='Display:',\n",
    "    tooltip='maximum:',\n",
    "    value=5,\n",
    "    min=1, \n",
    "    max = 30,\n",
    "    style=style )\n",
    "  howmany.style.handle_color = 'lightblue'\n",
    "  \n",
    "  ui = widgets.HBox([selector,Statistics_Explained,Glossaries, howmany])\n",
    "  out = widgets.interactive_output(NER_articles2, {'selector':selector,'Statistics_Explained': Statistics_Explained, 'Glossaries':Glossaries, 'howmany':howmany})\n",
    "\n",
    "\n",
    "  display(ui,out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 8,
        "row": 89,
        "width": 12
       }
      }
     }
    },
    "id": "PvIR0D3PuP6Z"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0dbf06a5fd45a694ce92fb589b6c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Combobox(value='', description='Search', options=('A COUNCIL RECOMMENDATION', 'AAA', 'ACER', 'A…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fc66618bdd4094a0546ed33b7a41d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NER_builder2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 3,
        "row": 97,
        "width": 12
       }
      }
     }
    },
    "id": "UPavJCsA9DDo"
   },
   "source": [
    "##### Case 3: Proposing phrases based on entity-relation-entity triplets (again Subject-Verb-Object relations)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "uBzhVCPmx40_"
   },
   "outputs": [],
   "source": [
    "def NER_articles3(selector,Statistics_Explained,Glossaries,howmany):\n",
    "\n",
    "  # If Statistics_Explained == True, then show only Statistics Explained Articles\n",
    "  if Statistics_Explained:\n",
    "    candidateArticles = ner[ner['SVOs_together'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('SE')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "\n",
    "  # If Glossaries == True, then show only Glossary articles\n",
    "  elif Glossaries:\n",
    "    candidateArticles = ner[ner['SVOs_together'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('GL')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "  \n",
    "  elif Statistics_Explained & Glossaries:\n",
    "    Statistics_Explained = False\n",
    "    candidateArticles = ner[ner['SVOs_together'].str.contains(selector)]\n",
    "    proposedArticles = candidateArticles[candidateArticles['Source'].str.contains('GL')]\n",
    "    proposedArticles = proposedArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    # drop duplicated titles\n",
    "    print(proposedArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in proposedArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n",
    "\n",
    "\n",
    "  else:\n",
    "    candidateArticles = ner[ner['SVOs_together'].str.contains(selector)]\n",
    "    candidateArticles = candidateArticles.drop_duplicates(subset=['Title'], keep='first')\n",
    "    print(candidateArticles.Title.count(),'Articles found.')\n",
    "    h = '<br/'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n for l,n in candidateArticles[[\"URL\",\"Title\"]][0:howmany].values])\n",
    "    return display(HTML(h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "mccfpMEz0i3o"
   },
   "outputs": [],
   "source": [
    "def NER_builder3():\n",
    "  style = {'description_width': 'initial'}\n",
    "\n",
    "  selector =  widgets.Combobox(\n",
    "    placeholder='Type something, e.g., EU, ASEA etc.',\n",
    "    options=list(ner['SVOs_together'].unique()),\n",
    "    description='Search')\n",
    "  \n",
    "  Statistics_Explained = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Only Statistics Explained',\n",
    "    style=style)\n",
    "  \n",
    "  Glossaries = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Only Glossaries',\n",
    "    style=style)\n",
    "  \n",
    "  howmany = widgets.IntSlider(\n",
    "    description='Display:',\n",
    "    tooltip='maximum:',\n",
    "    value=5,\n",
    "    min=1, \n",
    "    max = 30,\n",
    "    style=style )\n",
    "  howmany.style.handle_color = 'lightblue'\n",
    "  \n",
    "  ui = widgets.HBox([selector,Statistics_Explained,Glossaries, howmany])\n",
    "  out = widgets.interactive_output(NER_articles3, {'selector':selector,'Statistics_Explained': Statistics_Explained, 'Glossaries':Glossaries, 'howmany':howmany})\n",
    "\n",
    "\n",
    "  display(ui,out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 7,
        "row": 100,
        "width": 12
       }
      }
     }
    },
    "id": "JFdtgbCX0uHN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279fbade212d4af0be576a584e265fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Combobox(value='', description='Search', options=('a Council Recommendation on a comprehensive …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca9798fdbe84bada561acc61f1c44c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NER_builder3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 9,
        "row": 107,
        "width": 12
       }
      }
     }
    },
    "id": "F3L70z0u_I6b"
   },
   "source": [
    "#### **Alternative way of proposing related articles**\n",
    "***\n",
    "We have also implemented an alterantive way of both exploring related articles and constructing query.\n",
    "\n",
    "The purpose of this facet refers to users who have find an interesting article and want to easily find related research without browsing all existing publications themself. Also,it is very useful for users who have a specific research question and want to discover relevant articles.\n",
    "\n",
    "At first we discover a number of topics using LDA (Latent Dirichlet Allocation). This allows us to view each article as a mixture of these topics. By mapping a specific article into the topic space, we can find related articles.\n",
    "\n",
    "Articles are proposed according to a k-nearest algorithm in topic space based on Jensen - Shannon measure. The Jensen–Shannon divergence is a method of measuring the similarity between two probability distributions.\n",
    "\n",
    "In this widget a user can insert any kind of text like abstract, paragraph, full text, keywords, questions and find related articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "G6-D3uujBCMN"
   },
   "outputs": [],
   "source": [
    "### Get Nearest Papers (in Topic Space) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Frn8i3HcXEV-"
   },
   "outputs": [],
   "source": [
    "#Install/Load packages.\n",
    "\n",
    "import scispacy\n",
    "import spacy\n",
    "#import en_core_sci_lg\n",
    "import joblib\n",
    "\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from tqdm import tqdm\n",
    "from os.path import isfile\n",
    "\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3qM39L2nXEV-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:324: UserWarning: Trying to unpickle estimator LatentDirichletAllocation from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##### Latend Dirichlet Allocation ######\n",
    "#Prepare dataset.\n",
    "\n",
    "#all_texts = data['raw content']\n",
    "#all_texts[0][:500]\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    return [word.lemma_ for word in nlp(sentence) if not (word.like_num or word.is_stop or word.is_punct or word.is_space or len(word)==1)]\n",
    "    \n",
    "#vectorizer = CountVectorizer(tokenizer = spacy_tokenizer, min_df=2)\n",
    "#data_vectorized = vectorizer.fit_transform(tqdm(all_texts))\n",
    "#data_vectorized.shape\n",
    "\n",
    "#Most frequent words.\n",
    "\n",
    "#word_count = pd.DataFrame({'word': vectorizer.get_feature_names(), 'count': np.asarray(data_vectorized.sum(axis=0))[0]})\n",
    "\n",
    "#word_count.sort_values('count', ascending=False).set_index('word')[:20].sort_values('count', ascending=True).plot(kind='barh')\n",
    "#joblib.dump(vectorizer, 'vectorizer.csv')\n",
    "vectorizer = joblib.load('vectorizer.csv')\n",
    "data_vectorized = joblib.load('data_vectorized.csv')\n",
    "#joblib.dump(data_vectorized, 'data_vectorized.csv')\n",
    "#lda = LatentDirichletAllocation(n_components=50, random_state=0)\n",
    "#lda.fit(data_vectorized)\n",
    "#joblib.dump(lda, 'lda.csv')\n",
    "\n",
    "lda = joblib.load('lda.csv')\n",
    "\n",
    "def print_top_words(model, vectorizer, n_top_words):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"\\nTopic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "    \n",
    "#print_top_words(lda, vectorizer, n_top_words=25)\n",
    "doc_topic_dist = pd.DataFrame(lda.transform(data_vectorized))\n",
    "#doc_topic_dist.to_csv('doc_topic_dist.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "GLCfpwQdXgeP"
   },
   "outputs": [],
   "source": [
    "#Make variables 'title' and 'raw content' a list.\n",
    "\n",
    "tasks = data.set_index('title').to_dict()['raw content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TDEKaqO2XEWA"
   },
   "outputs": [],
   "source": [
    "article = data['raw content']\n",
    "\n",
    "def get_k_nearest_docs(doc_dist, k=5, lower=1950, upper=2020, get_dist=False):\n",
    "    '''\n",
    "    doc_dist: topic distribution (sums to 1) of one article\n",
    "    \n",
    "    Returns the index of the k nearest articles (as by Jensen–Shannon divergence in topic space). \n",
    "    '''\n",
    "    temp = doc_topic_dist\n",
    "\n",
    "    distances = temp.apply(lambda x: jensenshannon(x, doc_dist), axis=1)\n",
    "    k_nearest = distances[distances != 0].nsmallest(n=k).index\n",
    "    \n",
    "    if get_dist:\n",
    "        k_distances = distances[distances != 0].nsmallest(n=k)\n",
    "        return k_nearest, k_distances\n",
    "    else:\n",
    "        return k_nearest\n",
    "\n",
    "def plot_article_dna(title, width=20):\n",
    "    t = data[data.title == title].title.values[0]\n",
    "    doc_topic_dist[data.title== title].T.plot(kind='bar', legend=None, title=t, figsize=(width, 4))\n",
    "    plt.xlabel('Topic')\n",
    "\n",
    "def compare_dnas(title, recommendation_id, width=20):\n",
    "    t = data[data.title == recommendation_id].title.values[0]\n",
    "    temp = doc_topic_dist[data.title == title]\n",
    "    ymax = temp.max(axis=1).values[0]*1.25\n",
    "    temp = pd.concat([temp, doc_topic_dist[data.title == recommendation_id]])\n",
    "    temp.T.plot(kind='bar', title=t, figsize=(width, 4), ylim= [0, ymax])\n",
    "    plt.xlabel('Topic')\n",
    "    plt.legend(['Selection', 'Recommendation'])\n",
    "    \n",
    "def dna_tabs(title):\n",
    "    k = len(title)\n",
    "    outs = [widgets.Output() for i in range(k)]\n",
    "\n",
    "    tab = widgets.Tab(children = outs)\n",
    "    tab_titles = ['title ' + str(i+1) for i in range(k)]\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        tab.set_title(i, t)\n",
    "    display(tab)\n",
    "\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        with outs[i]:\n",
    "            ax = plot_article_dna(paper_ids[i])\n",
    "            plt.show(ax)\n",
    "\n",
    "def compare_tabs(title, recommendation_ids):\n",
    "    k = len(recommendation_ids)\n",
    "    outs = [widgets.Output() for i in range(k)]\n",
    "\n",
    "    tab = widgets.Tab(children = outs)\n",
    "    tab_titles = ['title ' + str(i+1) for i in range(k)]\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        tab.set_title(i, t)\n",
    "    display(tab)\n",
    "\n",
    "    for i, t in enumerate(tab_titles):\n",
    "        with outs[i]:\n",
    "            ax = compare_dnas(title, recommendation_ids[i])\n",
    "            plt.show(ax)\n",
    "\n",
    "def recommendation(title, k=5, lower=1950, plot_dna=False):\n",
    "    '''\n",
    "    Returns the title of the k papers that are closest (topic-wise) to the paper given by id.\n",
    "    '''\n",
    "    \n",
    "    print(data.title[data.title ==title].values[0])\n",
    "\n",
    "    recommended, dist= get_k_nearest_docs(doc_topic_dist[data.title == title].iloc[0], k, lower, 10, get_dist=True)\n",
    "    recommended = data.iloc[recommended].copy()\n",
    "    recommended['similarity'] = 1 - dist \n",
    "    \n",
    "    h = '<br/>'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n + '</a>' +' (Similarity: ' + \"{:.2f}\".format(s) + ')' for l, n, s in recommended[['url','title', 'similarity']].values])\n",
    "    display(HTML(h))\n",
    "    \n",
    "    if plot_dna:\n",
    "        compare_tabs(title, recommended.title.values)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "YMnu10xaXgeQ"
   },
   "outputs": [],
   "source": [
    "def relevant_articles(tasks, k=3, lower=1950, upper=2020):\n",
    "    tasks = [tasks] if type(tasks) is str else tasks \n",
    "    \n",
    "    \n",
    "    tasks_vectorized = vectorizer.transform(tasks)\n",
    "    tasks_topic_dist = pd.DataFrame(lda.transform(tasks_vectorized))\n",
    "   \n",
    "    \n",
    "    for index, bullet in enumerate(tasks):\n",
    "        print(bullet)\n",
    "       \n",
    "        recommended = get_k_nearest_docs(tasks_topic_dist.iloc[index], k, lower, upper)\n",
    "        recommended = data.iloc[recommended]\n",
    "        \n",
    "        h = '<br/>'.join(['<a href=\"' + l + '\" target=\"_blank\">'+ n + '</a>' for l, n in recommended[['url','title']].values])\n",
    "        display(HTML(h))\n",
    "        \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "hidden": true
       }
      }
     }
    },
    "id": "E6Ag5CX-XgeQ"
   },
   "outputs": [],
   "source": [
    "#First_version\n",
    "def relevant_articles_for_text():    \n",
    "    textW = widgets.Textarea(\n",
    "        value='Tourism',\n",
    "        placeholder='Type something',\n",
    "        description='',\n",
    "        disabled=False,\n",
    "        layout=Layout(width='90%', height='100px')\n",
    "    )\n",
    "\n",
    "    yearW = widgets.IntRangeSlider(min=1950, max=2020, value=[2010, 2020], description='Year Range', \n",
    "                               continuous_update=False, layout=Layout(width='40%'))\n",
    "    kWidget = widgets.IntSlider(value=10, description='Display', max=50, min=1, layout=Layout(width='25%'))\n",
    "    button = widgets.Button(description=\"Search\")\n",
    "    style = {'description_width': 'initial'}\n",
    "    display(VBox([HBox([kWidget, yearW], layout=Layout(width='90%', justify_content='space-around')),\n",
    "        textW, button], layout=Layout(align_items='center')))\n",
    "\n",
    "    def on_button_clicked(b):\n",
    "        clear_output()\n",
    "        display(VBox([HBox([kWidget, yearW], layout=Layout(width='90%', justify_content='space-around')),\n",
    "            textW, button], layout=Layout(align_items='center')))  \n",
    "        relevant_articles(textW.value, kWidget.value, yearW.value[0], yearW.value[1])\n",
    "        \n",
    "    button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "default_view": {
        "col": 0,
        "height": 6,
        "row": 117,
        "width": 12
       }
      }
     }
    },
    "id": "ttqUVag7XgeQ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc63ecb15a64f80bc7b31a1d1b33a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=10, description='Display', layout=Layout(width='25%'), max=50, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevant_articles_for_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "AIqq03AVXEWD"
   },
   "outputs": [],
   "source": [
    "#HTML('''<script>\n",
    "#code_show=true; \n",
    "#function code_toggle() {\n",
    "# if (code_show){\n",
    "# $('div.input').hide();\n",
    "# } else {\n",
    "# $('div.input').show();\n",
    "# }\n",
    "# code_show = !code_show\n",
    "#} \n",
    "#$( document ).ready(code_toggle);\n",
    "#</script>\n",
    "#<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "D_3_1_Use_Case_A_Version_3.ipynb",
   "provenance": []
  },
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "default_view",
    "version": 1,
    "views": {
     "default_view": {
      "cellMargin": 10,
      "defaultCellHeight": 40,
      "maxColumns": 12,
      "name": "active_view",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
